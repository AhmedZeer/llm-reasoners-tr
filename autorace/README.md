# AutoRace

This document will guide you to use the AutoRace to evaluate your reasoning chains (reproduce the experiments or apply it on your own datasets)

## Set the OpenAI_Key

```
export OPENAI_API_KEY= YOUR_OWN_OPEN_AI_KEY
```

## Reproduce the evaluation in paper

```
cd .../AutoRace
python autorace.py --dataset DATASET_NAME --prompt_type PROMPT_TYPE
```

The `DATASET_NAME` is one of `['gsm8k','strategyqa','AQuA','cosmos', 'multistep_arithmetic','word_sorting','logical_deduction']` and the `PROMPT_TYPE` can be found in `prompt.json`

## Evaluate your own result

Theorically, AutoRace can support any evaluation of Chain-of-Thought. In practice, you could first use the `AutoRace_criterion()` function in `AutoRace.py` to generate your own dataset's criterion prompt first and take `AutoRace_evaluation()` for evaluation. We showed an example from AQuA.

## Dataset format

```json
{
  "question": question in original dataset
  "gpt": a rationale generated by LLM
  "gt_answer": the ground truth answer of question in dataset
  "human_label": human annotator's 2-class classification on rationale's correctness. 0.0 indicates incorrect and 1.0 indicates correct.
}
```

Notice: AQuA do not have human_label in our collection process.
